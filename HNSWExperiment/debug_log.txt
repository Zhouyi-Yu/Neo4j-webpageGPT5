{"timestamp": "2025-12-17T08:43:52.853Z", "question": "recent papers on reinforcement learning", "answer": "Below I summarize the recent reinforcement‑learning (RL) papers found in the provided search hits, identify the University of Alberta authors in your Author Data, link them to the relevant papers, and group them by approach inferred from the paper titles.\n\nKey researchers (name — department) and linked papers (title) — with short description of approach (based on the title)\n\n- Witold Pedrycz — Electrical and Computer Engineering\n  - \"Reinforcement learning-assisted evolutionary algorithm: A survey and research opportunities\" (2024)\n  - Approach: survey of hybrid RL + evolutionary/optimization methods; focuses on combining RL with evolutionary algorithms and pointing out research opportunities.\n\n- Biao Huang — Chemical and Materials Engineering\n  - \"Online reinforcement learning for a continuous space system with experimental validation\" (2021)\n  - \"Reinforcement Learning in Process Industries: Review and Perspective\" (2024)\n  - \"A review On reinforcement learning: Introduction and applications in industrial process control\" (2020)\n  - \"Reinforcement learning approach to autonomous PID tuning\" (2022)\n  - Approach: industrial/process-control applications and methods (online RL, PID tuning, reviews of RL for process industries).\n\n- Marek Reformat — Electrical and Computer Engineering\n  - \"Reinforcement Learning for Topic Models\" (2023)\n  - Approach: applying RL methods to topic modeling / NLP-related model selection or inference.\n\n- Alan Lynch — Electrical and Computer Engineering\n  - \"Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving\" (2021)\n  - \"Quadrotor motion control using deep reinforcement learning\" (2021)\n  - Approach: autonomous systems and robotics — safe decision-making for highway driving and quadrotor motion control using deep RL.\n\n- Zhan Shu — Electrical and Computer Engineering\n  - \"Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving\" (2021)\n  - \"Topology Design for Data Center Networks Using Deep Reinforcement Learning\" (2023)\n  - Approach: RL for safety in autonomous driving and for combinatorial/architectural optimization (data‑center network topology design).\n\n- Petr Musilek — Electrical and Computer Engineering\n  - \"It’s All about Reward: Contrasting Joint Rewards and Individual Reward in Centralized Learning Decentralized Execution Algorithms\" (2023)\n  - Approach: multi‑agent RL / reward design and centralized-training decentralized-execution (CTDE) algorithms.\n\n- Yong Li — Civil and Environmental Engineering\n  - \"Spatial planning of urban communities via deep reinforcement learning\" (2023)\n  - Approach: spatial/urban planning using deep RL for planning and layout optimization.\n\n- Yu Hu — Electrical and Computer Engineering\n  - \"Reinforcement Learning Optimized Look-Ahead Energy Management of a Parallel Hybrid Electric Vehicle\" (2017)\n  - Approach: RL for energy management and control in hybrid electric vehicles (look‑ahead energy management).\n\n- David Zhu — Civil and Environmental Engineering\n  - \"A reinforcement learning-based ensemble forecasting framework for renewable energy forecasting\" (2025)\n  - Approach: applying RL to ensemble forecasting in renewable energy prediction.\n\n- Japan Trivedi — Civil and Environmental Engineering\n  - \"Reinforcement Learning for Multi-Well SAGD Optimization: A Policy Gradient Approach\" (2023)\n  - Approach: policy‑gradient RL for optimization in steam-assisted gravity drainage (SAGD) multi‑well operations (energy/oil field application).\n\nGrouping by approach (based on titles)\n- Surveys / methodological reviews:\n  - Witold Pedrycz (ECE): RL + evolutionary survey.\n  - Biao Huang (CME): several reviews on RL in process industries and industrial process control.\n\n- Industrial / process control / energy applications:\n  - Biao Huang (CME): online RL and PID tuning for industrial processes.\n  - Yu Hu (ECE): RL for hybrid vehicle energy management.\n  - Japan Trivedi (Civ/Env): RL for multi‑well SAGD optimization.\n  - David Zhu (Civ/Env): RL for renewable energy forecasting ensembles.\n\n- Robotics / autonomous systems / safety:\n  - Alan Lynch (ECE): quadrotor control, highway driving safety with RL.\n  - Zhan Shu (ECE): highway driving safety and network topology design (applied optimization).\n\n- Multi‑agent / reward design:\n  - Petr Musilek (ECE): reward structures in CTDE multi‑agent RL.\n\n- RL + optimization / evolutionary / combinatorial design:\n  - Witold Pedrycz (ECE): RL-assisted evolutionary algorithms.\n  - Zhan Shu (ECE): topology design for data centers.\n\n- RL for ML / NLP:\n  - Marek Reformat (ECE): RL applied to topic models.\n\n- Urban planning / spatial applications:\n  - Yong Li (Civ/Env): urban community spatial planning using deep RL.\n\nNotes and next steps\n- The descriptions above are inferred from paper titles in your semantic hits and the provided author affiliations. If you want, I can:\n  - Retrieve abstracts or full texts (if available) for any of these papers.\n  - Produce a short annotated bibliography (1–2 sentence summary per paper) for a selected subset (e.g., surveys, applications, robotics).\n  - Identify additional UAlberta authors working on RL beyond those in this author_data set.\n\nWhich of these areas or specific papers would you like me to expand on?", "intent": {"author": null, "department": null, "end_year": null, "intent": "OPEN_QUESTION", "scope": null, "second_author": null, "start_year": null, "topic": "reinforcement learning"}, "cypher": "UNWIND $titles AS title\nMATCH (p:Publication) WHERE p.title = title\nMATCH (p)<-[:PUBLISHED]-(ap:AuthorProfile)<-[:HAS_PROFILE]-(person:Person)\nWHERE person.userId IS NOT NULL OR person.ccid IS NOT NULL\nOPTIONAL MATCH (person)-[:BELONGS_TO]->(d:Department)\nRETURN p.title AS title, person.name AS author_name, collect(DISTINCT d.department) AS departments", "dbRows": [{"author_name": "Witold Pedrycz", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement learning-assisted evolutionary algorithm: A survey and research opportunities"}, {"author_name": "Biao Huang", "departments": ["Chemical and Materials Engineering"], "title": "Online reinforcement learning for a continuous space system with experimental validation"}, {"author_name": "Biao Huang", "departments": ["Chemical and Materials Engineering"], "title": "Reinforcement Learning in Process Industries: Review and Perspective"}, {"author_name": "Biao Huang", "departments": ["Chemical and Materials Engineering"], "title": "A review On reinforcement learning: Introduction and applications in industrial process control"}, {"author_name": "Marek Reformat", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement Learning for Topic Models"}, {"author_name": "Biao Huang", "departments": ["Chemical and Materials Engineering"], "title": "Reinforcement learning approach to autonomous PID tuning"}, {"author_name": "Alan Lynch", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving"}, {"author_name": "Zhan Shu", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving"}, {"author_name": "Petr Musilek", "departments": ["Electrical and Computer Engineering"], "title": "It’s All about Reward: Contrasting Joint Rewards and Individual Reward in Centralized Learning Decentralized Execution Algorithms"}, {"author_name": "Yong Li", "departments": ["Civil and Environmental Engineering"], "title": "Spatial planning of urban communities via deep reinforcement learning"}, {"author_name": "Yu Hu", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement Learning Optimized Look-Ahead Energy Management of a Parallel Hybrid Electric Vehicle"}, {"author_name": "Alan Lynch", "departments": ["Electrical and Computer Engineering"], "title": "Quadrotor motion control using deep reinforcement learning"}, {"author_name": "Zhan Shu", "departments": ["Electrical and Computer Engineering"], "title": "Topology Design for Data Center Networks Using Deep Reinforcement Learning"}, {"author_name": "David Zhu", "departments": ["Civil and Environmental Engineering"], "title": "A reinforcement learning-based ensemble forecasting framework for renewable energy forecasting"}, {"author_name": "Japan Trivedi", "departments": ["Civil and Environmental Engineering"], "title": "Reinforcement Learning for Multi-Well SAGD Optimization: A Policy Gradient Approach"}, {"author_name": "C Robert Koch", "departments": ["Mechanical Engineering"], "title": "Transfer of Reinforcement Learning-Based Powertrain Controllers From Model- to Hardware-in-the-Loop"}, {"author_name": "Japan Trivedi", "departments": ["Civil and Environmental Engineering"], "title": "Optimization of steam injection in SAGD using reinforcement learning"}, {"author_name": "Yong Li", "departments": ["Civil and Environmental Engineering"], "title": "A novel collaborative agent reinforcement learning framework based on an attention mechanism and disjunctive graph embedding for flexible job shop scheduling problem"}, {"author_name": "Zhan Shu", "departments": ["Electrical and Computer Engineering"], "title": "Model-free Predictive Optimal Iterative Learning Control using Reinforcement Learning"}, {"author_name": "Yu Hu", "departments": ["Electrical and Computer Engineering"], "title": "Reinforcement Learning for Hybrid and Plug-In Hybrid Electric Vehicle Energy Management: Recent Advances and Prospects"}], "semanticHits": [{"cited_by_count": 74, "publication_year": 2024, "score": 0.8093547821044922, "title": "Reinforcement learning-assisted evolutionary algorithm: A survey and research opportunities"}, {"cited_by_count": 45, "publication_year": 2021, "score": 0.7926740646362305, "title": "Online reinforcement learning for a continuous space system with experimental validation"}, {"cited_by_count": 46, "publication_year": 2024, "score": 0.7867999076843262, "title": "Reinforcement Learning in Process Industries: Review and Perspective"}, {"cited_by_count": 587, "publication_year": 2020, "score": 0.7851967811584473, "title": "A review On reinforcement learning: Introduction and applications in industrial process control"}, {"cited_by_count": 5, "publication_year": 2023, "score": 0.7772135734558105, "title": "Reinforcement Learning for Topic Models"}, {"cited_by_count": 121, "publication_year": 2022, "score": 0.76959228515625, "title": "Reinforcement learning approach to autonomous PID tuning"}, {"cited_by_count": 6, "publication_year": 2021, "score": 0.7594966888427734, "title": "Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving"}, {"cited_by_count": 6, "publication_year": 2021, "score": 0.7594966888427734, "title": "Reinforcement Learning Based Safe Decision Making for Highway Autonomous Driving"}, {"cited_by_count": 2, "publication_year": 2023, "score": 0.7556071281433105, "title": "It’s All about Reward: Contrasting Joint Rewards and Individual Reward in Centralized Learning Decentralized Execution Algorithms"}, {"cited_by_count": 96, "publication_year": 2023, "score": 0.754549503326416, "title": "Spatial planning of urban communities via deep reinforcement learning"}, {"cited_by_count": 385, "publication_year": 2017, "score": 0.7526578903198242, "title": "Reinforcement Learning Optimized Look-Ahead Energy Management of a Parallel Hybrid Electric Vehicle"}, {"cited_by_count": 15, "publication_year": 2021, "score": 0.7517480850219727, "title": "Quadrotor motion control using deep reinforcement learning"}, {"cited_by_count": 0, "publication_year": 2023, "score": 0.7511224746704102, "title": "Topology Design for Data Center Networks Using Deep Reinforcement Learning"}, {"cited_by_count": 6, "publication_year": 2025, "score": 0.7455921173095703, "title": "A reinforcement learning-based ensemble forecasting framework for renewable energy forecasting"}, {"cited_by_count": 1, "publication_year": 2023, "score": 0.7454452514648438, "title": "Reinforcement Learning for Multi-Well SAGD Optimization: A Policy Gradient Approach"}, {"cited_by_count": 1, "publication_year": 2025, "score": 0.7453441619873047, "title": "Transfer of Reinforcement Learning-Based Powertrain Controllers From Model- to Hardware-in-the-Loop"}, {"cited_by_count": 29, "publication_year": 2021, "score": 0.7452807426452637, "title": "Optimization of steam injection in SAGD using reinforcement learning"}, {"cited_by_count": 37, "publication_year": 2024, "score": 0.7448863983154297, "title": "A novel collaborative agent reinforcement learning framework based on an attention mechanism and disjunctive graph embedding for flexible job shop scheduling problem"}, {"cited_by_count": 4, "publication_year": 2022, "score": 0.7446203231811523, "title": "Model-free Predictive Optimal Iterative Learning Control using Reinforcement Learning"}, {"cited_by_count": 227, "publication_year": 2019, "score": 0.7440066337585449, "title": "Reinforcement Learning for Hybrid and Plug-In Hybrid Electric Vehicle Energy Management: Recent Advances and Prospects"}]}
